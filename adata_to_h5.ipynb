{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48900226-d4dd-4723-827a-76e40977f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Sep 27 23:23:03 2019\n",
    "\n",
    "@author: fenghuijian\n",
    "\n",
    "Introduction: We use the Hierarchical Data Format V5(hdf5) file for data transmission between Python platform and R platform,\n",
    "so as to achieve the purpose of reading data quickly and conveniently.Below, we will abbreviate hdf5 as h5.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "###  import the packages\n",
    "from asyncio.events import get_running_loop\n",
    "import scipy\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import anndata\n",
    "from pandas.api.types import is_string_dtype, is_categorical_dtype, is_bool_dtype, is_float_dtype, is_integer_dtype, is_object_dtype\n",
    "import h5py\n",
    "from typing import Union\n",
    "import re\n",
    "import os\n",
    "\n",
    "from scipy.sparse.sputils import matrix\n",
    "\n",
    "### adata write the h5 file\n",
    "def write_h5(adata: anndata.AnnData,\n",
    "             file: Union[str, None] = None,\n",
    "             assay_name: str = 'RNA',\n",
    "             save_X:bool = True,\n",
    "             save_graph:bool = True\n",
    "             ) -> None:\n",
    "    \"\"\"\n",
    "    The adata object is converted to H5 file that R can read\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    adata : anndata.AnnData.\n",
    "    file : The h5 file\n",
    "    assay_name : Denotes which omics data to save. Default is 'RNA'. Available options are:\n",
    "                'RNA': means that this omics data is scRNA-seq data\n",
    "                'spatial': means that this omics data is spatial data generated by 10x Genomics Visium toolkits\n",
    "    save_X : In scanpy working pipeline, the primary expression matrix is located in adata.X before gene selection and scalization. After adata.raw = adata\n",
    "             as well as gene selection and scalization, The primary expression matrix isn't located in adata.X but in adata.raw.X. \n",
    "             save_X will be valid if adata.raw exists. Default is True.True means to save adata.X and Falsed means not to save adata.X.\n",
    "             save_X will be unvalid and adata.X will be saved by defualt when adata.raw is None.\n",
    "    save_graph : Default is True, determing whether to save the graph(cell-cell similarity network). scanpy graph is different from seruat graph. Their relationship are \n",
    "                 set {\"distances\": \"knn\", \"connectivities\": \"snn\"} roughly.\n",
    "    ----------\n",
    "\n",
    "    Usage:\n",
    "    -----\n",
    "    >>> import diopy\n",
    "    >>> diopy.output.write_h5(adata = adata, file='scdata.h5',save_raw=True,save_graph=True)\n",
    "    -----\n",
    "    \"\"\"\n",
    "    # glabol function\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "    if file is None:\n",
    "        raise OSError(\"No such file or directory\")\n",
    "    if not isinstance(adata, anndata.AnnData):\n",
    "        raise TypeError(\"object '%s' class is not anndata.AnnData object\" % namestr(adata, globals())[0])\n",
    "    # w Create file, truncate if exists\n",
    "    h5 = h5py.File(name=file, mode=\"w\")\n",
    "    try:\n",
    "        adata_to_h5(adata=adata, h5=h5,assay_name=assay_name,save_X=save_X,save_graph=save_graph)\n",
    "        h5.attrs['assay_name'] = np.array([assay_name], dtype=h5py.special_dtype(vlen=str))\n",
    "    except Exception as e:\n",
    "        print('Error:', e)\n",
    "    finally:\n",
    "        h5.close()\n",
    "    return\n",
    "\n",
    "\n",
    "### adata convert to the h5 file \n",
    "def adata_to_h5(adata: anndata.AnnData,\n",
    "                h5: h5py.File,\n",
    "                assay_name: Union[str, None] = 'RNA',\n",
    "                save_graph:bool = False,\n",
    "                save_X:bool = False\n",
    "                ) -> None:\n",
    "    \"\"\"\n",
    "    The adata object is converted to H5 file that R can read\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    adata : anndata.AnnData.\n",
    "    file : The h5 file\n",
    "    assay_name : Denotes which omics data to save. Default is 'RNA'. Available options are:\n",
    "                'RNA': means that this omics data is scRNA-seq data\n",
    "                'spatial': means that this omics data is spatial data generated by 10x Genomics Visium toolkits\n",
    "    save_X : In scanpy working pipeline, the primary expression matrix is located in adata.X before gene selection and scalization. After adata.raw = adata\n",
    "             as well as gene selection and scalization, The primary expression matrix isn't located in adata.X but in adata.raw.X. \n",
    "             save_X will be valid if adata.raw exists. Default is True.True means to save adata.X and Falsed means not to save adata.X.\n",
    "             save_X will be unvalid and adata.X will be saved by defualt when adata.raw is None.\n",
    "    save_graph : Default is True, determing whether to save the graph(cell-cell similarity network). scanpy graph is different from seruat graph. Their relationship are \n",
    "                 set {\"distances\": \"knn\", \"connectivities\": \"snn\"} roughly.\n",
    "    ----------\n",
    "\n",
    "    Usage:\n",
    "    -----\n",
    "    >>> import diopy\n",
    "    >>> diopy.output.write_h5(adata = adata, file='scdata.h5',save_raw=True,save_graph=True)\n",
    "    -----\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    The adata object is converted to H5 file that R can read\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    adata: anndata.AnnData\n",
    "    h5: h5py.File\n",
    "    assy_name : Denotes which omics data to save. Default is 'RNA'. Available options are:\n",
    "                'RNA': means that this omics data is scRNA-seq data\n",
    "                'spatial': means that this omics data is spatial data generated by 10x Genomics Visium toolkits\n",
    "    save_raw : Default is True, determining whether to save adata.raw.X. adata.X and adata.raw.X will be changed in the scanpy pipeline. None: save adata.X & adata.raw.X \n",
    "               when adata.X.shape == adata.raw.X.shape. True: save adata.raw.X in any case. Fasle: save adata.X in any case.\n",
    "    save_graph : Default is False , determing whether to save the graph(cell-cell similarity network). scanpy graph is different from seruat graph. Their relationship are \n",
    "                 set {\"distances\": \"knn\", \"connectivities\": \"snn\"} roughly.\n",
    "    ----------\n",
    "\n",
    "    Usage:\n",
    "    ------\n",
    "    >>> adata_to_h5(adata=adata,h5=h5, assay_name='RNA')\n",
    "    >>>\n",
    "    -----\n",
    "\n",
    "    \"\"\"\n",
    "    adata_raw = adata.raw\n",
    "    data = h5.create_group('data')\n",
    "    var = h5.create_group('var')\n",
    "    # --- save the data if adata.raw exists\n",
    "    df_to_h5(df=adata.obs, h5=h5, gr_name='obs') # save the obs\n",
    "    if not adata_raw is None:    \n",
    "        if save_X:\n",
    "            # save as X (scale)\n",
    "            matrix_to_h5(mat=adata.X, h5=data, gr_name='X')\n",
    "            df_to_h5(df=adata.var, h5=var, gr_name='X')\n",
    "            # save as rawX (data)\n",
    "            matrix_to_h5(mat=adata_raw.X, h5=data, gr_name='rawX')\n",
    "            df_to_h5(df=adata_raw.var, h5=var, gr_name='rawX')\n",
    "        else:\n",
    "            # save as X (data)\n",
    "            matrix_to_h5(mat=adata_raw.X, h5=data, gr_name='X')\n",
    "            df_to_h5(df=adata_raw.var, h5=var, gr_name='X')\n",
    "    else:\n",
    "        matrix_to_h5(mat=adata.X, h5=data, gr_name='X')\n",
    "        df_to_h5(df=adata.var,h5=var, gr_name='X')\n",
    "    #--- save the dimension reduction\n",
    "    if len(adata.obsm.keys())>0:\n",
    "        dimR = h5.create_group('dimR')\n",
    "        for k in [k for k in adata.obsm.keys()]:\n",
    "            K = re.sub(\"^.*_\", \"\", k).upper()\n",
    "            dimR.create_dataset(K, data=adata.obsm[k], dtype=np.float32)\n",
    "    if save_graph:\n",
    "        \n",
    "        gr = adata.obsp\n",
    "        if len(gr.keys()) > 0:\n",
    "            graphs = h5.create_group('graphs')\n",
    "            gra_dict = {\"distances\": \"knn\", \"connectivities\": \"snn\"}\n",
    "        #--- save the neighbor graphs\n",
    "            for g in gra_dict.keys():\n",
    "                matrix_to_h5(mat=gr[g], h5=graphs, gr_name=gra_dict[g])\n",
    "    if assay_name == 'spatial':\n",
    "        spatial_to_h5(adata=adata, h5=h5, gr_name=assay_name)\n",
    "    # only save the uns color\n",
    "    uns = h5.create_group('uns')\n",
    "    for c in adata.uns_keys():\n",
    "        if 'colors' in c:\n",
    "            # uns.create_dataset(c, data=adata.uns[c])\n",
    "            uns.create_dataset(c,data=np.array(adata.uns[c]).astype(np.object))\n",
    "    # save the layers for the some data type, this dim is same as the X, and the varm gene same as the X\n",
    "    if save_X:\n",
    "        if len(adata.layers.keys())>0: \n",
    "            layers = h5.create_group('layers')\n",
    "            for l in adata.layers.keys():\n",
    "                matrix_to_h5(mat=adata.layers[l], h5=layers, gr_name=l)\n",
    "        if len(adata.varm.keys())>0:\n",
    "            varm = h5.create_group('varm')\n",
    "            for j in adata.varm.keys():\n",
    "                varm.create_dataset(j, data=adata.varm[j], dtype=np.float32)\n",
    "    return\n",
    "#--- To be continued\n",
    "\n",
    "\n",
    "\n",
    "### pandas dataframe save to the h5 file\n",
    "def df_to_h5(df: pd.DataFrame,\n",
    "             h5: Union[h5py.File,h5py.Group],\n",
    "             gr_name: Union[str, None] = None\n",
    "             ) -> None:\n",
    "    \"\"\"\n",
    "    pandas.core.frame.DataFrame be converted the h5 format that R can read in\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.core.frame.Data.Frame\n",
    "    h5 : h5py.File\n",
    "    gr_name : the group name in the h5py.File \n",
    "    ----------\n",
    "\n",
    "    Usage:\n",
    "    -----\n",
    "    >>> import PyIOH5\n",
    "    >>> import h5py\n",
    "    >>> h5 = h5py.File('test.h5', 'w')\n",
    "    >>> PyIOH5.df_to_h5(df=df, h5=h5, gr_name = 'dataframe')\n",
    "    >>> h5.close()\n",
    "    -----\n",
    "    \"\"\"\n",
    "    if gr_name not in h5.keys():\n",
    "        h5df = h5.create_group(gr_name)\n",
    "    else:\n",
    "        h5df = h5[gr_name]\n",
    "    cate_dict = {}\n",
    "    df.index = df.index.astype(str)\n",
    "    h5df.create_dataset(name='index', data=df.index.values.astype(h5py.special_dtype(vlen=str))) # rownames to str\n",
    "    if len(df.columns)>0:\n",
    "        dfcol = df.columns.copy()\n",
    "        dfcol = dfcol.astype(str)\n",
    "        h5df.create_dataset(name='colnames', data=dfcol.values.astype(h5py.special_dtype(vlen=str))) # colnames to str\n",
    "    for k in df.keys():\n",
    "        if is_categorical_dtype(df[k]):\n",
    "            h5df.create_dataset(name=k, data=df[k].cat.codes.values)\n",
    "            h5df[k].attrs['origin_dtype'] = 'category'\n",
    "            cate_dtype = df[k].cat.categories.values.dtype\n",
    "            if np.issubdtype(cate_dtype, np.integer):\n",
    "                cate_dict[k] = df[k].cat.categories.values\n",
    "            if np.issubdtype(cate_dtype, np.floating):\n",
    "                cate_dict[k] = df[k].cat.categories.values\n",
    "            if np.issubdtype(cate_dtype, np.object):\n",
    "                cate_dict[k] = df[k].cat.categories.values.astype(h5py.special_dtype(vlen=str))\n",
    "        if is_object_dtype(df[k]):\n",
    "            str_to_cate = pd.Categorical(df[k].astype('str'))\n",
    "            h5df.create_dataset(name=k, data=str_to_cate.codes)\n",
    "            h5df[k].attrs['origin_dtype'] = 'string'\n",
    "            cate_dict[k] = str_to_cate.categories.values.astype(h5py.special_dtype(vlen=str))\n",
    "        if is_bool_dtype(df[k]):\n",
    "            bool_to_int = df[k].astype(int)\n",
    "            h5df.create_dataset(name=k, data=bool_to_int.values)\n",
    "            h5df[k].attrs['origin_dtype'] = 'bool'\n",
    "        if is_float_dtype(df[k]) or is_integer_dtype(df[k]):\n",
    "            h5df.create_dataset(name=k, data=df[k].values)\n",
    "            h5df[k].attrs['origin_dtype'] = 'number'\n",
    "    if len(cate_dict.keys())>0:\n",
    "        print(cate_dict.keys())\n",
    "        h5df_cate = h5df.create_group('category')\n",
    "        print(h5df_cate.name)\n",
    " \n",
    "\n",
    "        for ca in cate_dict.keys():\n",
    "            print(ca)\n",
    "        \n",
    "            #print(cate_dict[ca])\n",
    "            h5df_cate.create_dataset(name=ca, data=cate_dict[ca])  ######注意不是names https://docs.h5py.org/en/stable/high/group.html\n",
    "    return \n",
    "#     if gr_name not in h5.keys():\n",
    "#         h5df = h5.create_group(gr_name)\n",
    "#     else:\n",
    "#         h5df = h5[gr_name]\n",
    "#     df.index = df.index.astype(str)\n",
    "#     h5df.create_dataset(name='index', data=df.index.values.astype(h5py.special_dtype(vlen=str))) # rownames to str\n",
    "#     if len(df.columns)>0:\n",
    "#         dfcol = df.columns.copy()\n",
    "#         dfcol = dfcol.astype(str)\n",
    "#         h5df.create_dataset(name='colnames', data=dfcol.values.astype(h5py.special_dtype(vlen=str))) # colnames to str\n",
    "#     for k in df.keys():\n",
    "#         if is_categorical_dtype(df[k]):\n",
    "#             h5df.create_dataset(name=k, data=df[k].cat.codes.values)\n",
    "#             h5df[k].attrs['origin_dtype'] = 'category'\n",
    "#             cate_dtype = df[k].cat.categories.values.dtype\n",
    "#             if np.issubdtype(cate_dtype, np.integer):\n",
    "#                 h5df.create_dataset(name=k+'_levels', data=df[k].cat.categories.values)\n",
    "#             if np.issubdtype(cate_dtype, np.floating):\n",
    "#                 h5df.create_dataset(name=k+'_levels', data=df[k].cat.categories.values)\n",
    "#             if np.issubdtype(cate_dtype, np.object):\n",
    "#                 h5df.create_dataset(name=k+'_levels', data=df[k].cat.categories.values.astype(h5py.special_dtype(vlen=str)))\n",
    "#         if is_object_dtype(df[k]):\n",
    "#             str_to_cate = pd.Categorical(df[k].astype('str'))\n",
    "#             h5df.create_dataset(name=k, data=str_to_cate.codes)\n",
    "#             h5df[k].attrs['origin_dtype'] = 'string'\n",
    "#             h5df.create_dataset(name=k+'_levels', data=str_to_cate.categories.values.astype(h5py.special_dtype(vlen=str)))\n",
    "#         if is_bool_dtype(df[k]):\n",
    "#             bool_to_int = df[k].astype(int)\n",
    "#             h5df.create_dataset(name=k, data=bool_to_int.values)\n",
    "#             h5df[k].attrs['origin_dtype'] = 'bool'\n",
    "#         if is_float_dtype(df[k]) or is_integer_dtype(df[k]):\n",
    "#             h5df.create_dataset(name=k, data=df[k].values)\n",
    "#             h5df[k].attrs['origin_dtype'] = 'number'\n",
    "#     return \n",
    "\n",
    "### matrix save to the h5 file\n",
    "def matrix_to_h5(mat,\n",
    "                 h5: Union[h5py.Group, h5py.File],\n",
    "                 gr_name: Union[str, None] = None\n",
    "                 ) -> None:\n",
    "    \"\"\"\n",
    "    The matrix(scipy.sparse.csr.csr_matrix or np.ndarray) is converted to the matrix in h5 format or is stored into the h5 file that R can read.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    mat : scipy.sparse.csr.csr_matrix or numpy.ndarray\n",
    "    h5 : h5py.File\n",
    "    gr_name : the group name in the h5py.File \n",
    "    ----------\n",
    "\n",
    "    Usage:\n",
    "    -----\n",
    "    >>> import PyIOH5\n",
    "    >>> import h5py\n",
    "    >>> from scipy import sparse \n",
    "    >>> indptr = np.array([0, 2, 3, 6])\n",
    "    >>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
    "    >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
    "    >>> spm = sparse.csr_matrix((data, indices, indptr), shape=(3, 3))\n",
    "    >>> h5 = h5py.File('test.h5', 'w')\n",
    "    >>> PyIOH5.matrix_to_h5(mat = spm,h5 = h5,gr_name = 'sparsematrix')\n",
    "    >>>\n",
    "    -----\n",
    "    \"\"\"\n",
    "    if gr_name not in h5.keys():\n",
    "        h5mat = h5.create_group(gr_name)\n",
    "    else:\n",
    "        h5mat = h5[gr_name]\n",
    "    if isinstance(mat, scipy.sparse.csr.csr_matrix):\n",
    "        h5mat_i = h5mat.create_dataset(\"indices\", data=mat.indices)\n",
    "        h5mat_p = h5mat.create_dataset(\"indptr\", data=mat.indptr)\n",
    "        h5mat_x = h5mat.create_dataset(\"values\", data=mat.data, dtype=np.float32)\n",
    "        h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "        h5mat.attrs[\"datatype\"] = \"SparseMatrix\"\n",
    "    elif isinstance(mat, np.ndarray):\n",
    "        h5mat_mat = h5mat.create_dataset(\"matrix\", data=mat, dtype=np.float32)\n",
    "        h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "        h5mat.attrs['datatype'] = 'Array'\n",
    "    elif 'core' in dir(anndata):\n",
    "        if isinstance(mat, anndata.core.views.SparseCSRView):\n",
    "            h5mat_i = h5mat.create_dataset(\"indices\", data=mat.indices)\n",
    "            h5mat_p = h5mat.create_dataset(\"indptr\", data=mat.indptr)\n",
    "            h5mat_x = h5mat.create_dataset(\"values\", data=mat.data, dtype=np.float32)\n",
    "            h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "            h5mat.attrs[\"datatype\"] = \"SparseMatrix\"\n",
    "        elif isinstance(mat, anndata.core.views.ArrayView):\n",
    "            h5mat_mat = h5mat.create_dataset(\"matrix\", data=mat, dtype=np.float32)\n",
    "            h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "            h5mat.attrs['datatype'] = 'Array'\n",
    "    elif 'base' in dir(anndata):\n",
    "        if isinstance(mat, anndata.base.ArrayView):\n",
    "            h5mat_mat = h5mat.create_dataset(\"matrix\", data=mat, dtype=np.float32)\n",
    "            h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "            h5mat.attrs['datatype'] = 'Array'\n",
    "        elif isinstance(mat, anndata.base.SparseCSRView):\n",
    "            h5mat_i = h5mat.create_dataset(\"indices\", data=mat.indices)\n",
    "            h5mat_p = h5mat.create_dataset(\"indptr\", data=mat.indptr)\n",
    "            h5mat_x = h5mat.create_dataset(\"values\", data=mat.data, dtype=np.float32)\n",
    "            h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "            h5mat.attrs[\"datatype\"] = \"SparseMatrix\"\n",
    "    elif '_core' in dir(anndata):\n",
    "        if isinstance(mat, anndata._core.views.ArrayView):\n",
    "            h5mat_mat = h5mat.create_dataset(\"matrix\", data=mat, dtype=np.float32)\n",
    "            h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "            h5mat.attrs['datatype'] = 'Array'\n",
    "        elif isinstance(mat, anndata._core.views.SparseCSRView):\n",
    "            h5mat_i = h5mat.create_dataset(\"indices\", data=mat.indices)\n",
    "            h5mat_p = h5mat.create_dataset(\"indptr\", data=mat.indptr)\n",
    "            h5mat_x = h5mat.create_dataset(\"values\", data=mat.data, dtype=np.float32)\n",
    "            h5mat_dims = h5mat.create_dataset(\"dims\", data=mat.shape)\n",
    "            h5mat.attrs[\"datatype\"] = \"SparseMatrix\"\n",
    "    else:\n",
    "        raise TypeError(\"The adata.X version is not supported\")\n",
    "    return\n",
    "\n",
    "\n",
    "def spatial_to_h5(adata,h5,gr_name = 'spatial'):\n",
    "    \"\"\"\n",
    "    The spatial messages are converted to the into the h5 file that R can read.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    adata: anndata.AnnData\n",
    "    h5 : h5py.File\n",
    "    gr_name : The group name in the h5py.File. Default is 'spatial'\n",
    "    ----------\n",
    "\n",
    "    Usage:\n",
    "    -----\n",
    "    >>> spatial_to_h5(adata=adata, h5=h5, gr_name='spatial')\n",
    "    >>>\n",
    "    -----\n",
    "    \"\"\"\n",
    "    sp = h5.create_group('spatial')\n",
    "    for sampleid in adata.uns[gr_name].keys():\n",
    "        sid_h5 = sp.create_group(sampleid)\n",
    "        #--- save tissue image\n",
    "        sid_image_h5 = sid_h5.create_group('image')\n",
    "        simage = adata.uns[gr_name][sampleid]['images']\n",
    "        for im in simage.keys():\n",
    "            sid_image_h5.create_dataset(im, data=simage[im])\n",
    "        #--- save tissue coordinate\n",
    "        v1 = ['in_tissue','array_row','array_col']\n",
    "        df = adata.obs[v1]\n",
    "        coor_df = pd.concat([df,pd.DataFrame(adata.obsm['spatial'],index = df.index, columns=['image_1', 'image_2'])],axis=1)\n",
    "        df_to_h5(df = coor_df, h5 = sid_h5, gr_name = 'coor')\n",
    "        #--- save the scalefactor\n",
    "        sid_scalefactor_h5 = sid_h5.create_group('scalefactors')\n",
    "        sf = adata.uns[gr_name][sampleid]['scalefactors']\n",
    "        for k in sf.keys():\n",
    "            sid_scalefactor_h5.create_dataset(k, data=sf[k])\n",
    "    return   \n",
    "\n",
    "def write_rds(adata: Union[str, None] = None,\n",
    "\t          file: Union[str, None] = None,\n",
    "             object_type:str = 'seurat',\n",
    "             assay_name: str = 'RNA'\n",
    "            ) -> None:\n",
    "    rfile = re.sub('.rds','_tmp.h5',file)\n",
    "    write_h5(adata=adata, file=rfile, assay_name=assay_name)\n",
    "    current_path = os.path.abspath(__file__)\n",
    "    diorc_file= os.path.abspath(os.path.dirname(current_path) + os.path.sep + \".\") + '/R/diorC.R'\n",
    "    os.system('Rscript ' + diorc_file +' -r '+ rfile +' -t '+ object_type + ' -a '+assay_name)\n",
    "    return \n",
    "\n",
    "## to be continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ffe17ca-b206-43fb-aac9-8e3baa593fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dynamo/lib/python3.7/site-packages/ipykernel_launcher.py:236: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['batch', 'sample', 'disease_group', 'phase', 'doublet_info', 'leiden'])\n",
      "/obs/category\n",
      "batch\n",
      "sample\n",
      "disease_group\n",
      "phase\n",
      "doublet_info\n",
      "leiden\n",
      "dict_keys(['features', 'ambiguous_features', 'spliced_features', 'unspliced_features'])\n",
      "/var/X/category\n",
      "features\n",
      "ambiguous_features\n",
      "spliced_features\n",
      "unspliced_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dynamo/lib/python3.7/site-packages/ipykernel_launcher.py:176: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "h5.close()\n",
    "file=\"fortest_tmp3.h5\"\n",
    "assay_name=\"RNA\"   \n",
    "adata=\"a_test.h5ad\"\n",
    "adata=sc.read_h5ad(adata)\n",
    "#              assay_name: str = 'RNA',\n",
    "#              save_X:bool = True,\n",
    "#              save_graph:bool = True    \n",
    "    \n",
    "h5 = h5py.File(name=file, mode=\"w\")\n",
    "adata_to_h5(adata=adata, h5=h5,assay_name=assay_name,save_X=True,save_graph=True)\n",
    "h5.attrs['assay_name'] = np.array([assay_name], dtype=h5py.special_dtype(vlen=str))\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa38b7b2-90f1-4a76-bd5b-9801e3691e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm fortest_tmp3.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66a97c-d289-4429-906c-5814d81b7459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed093ccd-7c58-4d3e-b2b6-7b649445e4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7330e-bd53-49a8-a825-aa6579fa9b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b9afd-a659-42be-94b0-bc304962672a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ae30319-6776-4685-8813-81911d4c5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_name='obs'\n",
    "df=\"adata.obs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "299b2a26-a6e8-48b7-8357-81e8de131733",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21498/4115365573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#df.index = df.index.astype(str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mh5df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# rownames to str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "    if gr_name not in h5.keys():\n",
    "        h5df = h5.create_group(gr_name)\n",
    "    else:\n",
    "        h5df = h5[gr_name]\n",
    "    cate_dict = {}\n",
    "    #df.index = df.index.astype(str)\n",
    "    h5df.create_dataset(name='index', data=df.index.values.astype(h5py.special_dtype(vlen=str))) # rownames to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddbbca-9ef0-4e8b-be8c-46e5b9c4fd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87729b16-c60c-4a57-bc2b-0a0a8515c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yyp/codeproject/format'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84e6e1-79ed-43cc-af32-2672bd90f998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d85f89c-878a-461c-9903-bf476429c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"fortest_tmp.h5\"\n",
    "h5 = h5py.File(name=file, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a67cd3cd-3b6e-4517-9707-eebb2f336a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dynamo/lib/python3.7/site-packages/anndata/compat/__init__.py:182: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/dynamo/lib/python3.7/site-packages/anndata/compat/__init__.py:182: FutureWarning: Moving element from .uns['neighbors']['connectivities'] to .obsp['connectivities'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "adata=sc.read_h5ad(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66fc1311-0955-4b67-83bf-96bad14aaaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24969x19860 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 45290487 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c8732-1336-4ad7-830d-4668d9bcd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    adata_raw = adata.raw\n",
    "    data = h5.create_group('data')\n",
    "    var = h5.create_group('var')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
